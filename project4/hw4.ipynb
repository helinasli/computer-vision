{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helin Aslı Aksoy\n",
    "150200705\n",
    "\n",
    "Running time is about 15-20 minute.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "Please read the instructions before starting.\n",
    "\n",
    "- Only use array manipulation functions from ```numpy```. (Similar to last homework)\n",
    "- You can use ```PIL``` for reading images and ```ipywidgets``` and ```display``` to display them.\n",
    "- Use ```numpy``` operations and arrays as much as possible for performance criteria. Try to avoid using for-loops as they will drastically slow down your implementations for large-scale images. Slow implementations will have a penalty during grading.\n",
    "- You can overwrite the template as long as the above conditions are not violated and the functionality is kept the same. Keep in mind that you will **only** submit the ```hw4.ipynb``` notebook and ```previous_homework.py``` file\n",
    "\n",
    " Fill the the marked areas in the cells for each question. \n",
    "\n",
    "- - -\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Question 1 [80pt]\n",
    "\n",
    "In this question, you will implement Lucas Kanade optical flow algorithm.\n",
    "\n",
    "- We begin with calculating $I_x$, $I_y$, and $I_t$.\n",
    "- For each window, formulate Least-Squares according to the equality $I_x u + I_y v + I_t = 0$\n",
    "- Ignore ill-conditioned pixels that have the small minimum eigen value for the covariance matrix $A^TA$ where $A$ denotes the matrix $[I_x, I_y]$ for the points in a window $\\mathcal{W}_p$ at pixel $p$.\n",
    "- Solve the Least-Squares equations for $u$ and $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def video_to_numpy(path: str) -> np.ndarray:\n",
    "    \"\"\" Convert the video frames into a numpy array\n",
    "\n",
    "    Args:\n",
    "        path (str): path of the video\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 3D numpy array of shape (T, H, W)\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frames = []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    while ret:\n",
    "        grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        img_arr = grayFrame[::3, ::3]\n",
    "        frames.append(img_arr)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "    return np.stack(frames).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "from previous_homework import sobel_horizontal, sobel_vertical, gaussian_filter\n",
    "\n",
    "# Determine a value\n",
    "WINDOW_SIZE = 15\n",
    "THRESHOLD =  0.001\n",
    "\n",
    "image_sequence = video_to_numpy(\"video.mp4\")\n",
    "u_sequence = np.zeros(image_sequence.shape, dtype=np.float32)\n",
    "v_sequence = np.zeros(image_sequence.shape, dtype=np.float32)\n",
    "\n",
    "\n",
    "def derivatives(img: np.ndarray, next_img: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\" Calculate derivative images.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): 2D gray video frame of shape (H, W)\n",
    "        next_img (np.ndarray): 2D next gray video frame of shape (H, W)\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "            - x derivative I_x of shape (H, W)\n",
    "            - y derivative I_y of shape (H, W)\n",
    "            - temporal derivative I_t of shape (H, W)\n",
    "    \"\"\"\n",
    "    Ix = sobel_horizontal(img)\n",
    "    Iy = sobel_vertical(img)\n",
    "    It = next_img - img\n",
    "\n",
    "    return Ix, Iy, It\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def lucas_kanade(x_derivative: np.ndarray,\n",
    "                 y_derivative: np.ndarray,\n",
    "                 time_derivative: np.ndarray,\n",
    "                 window_size: int,\n",
    "                 threshold: float\n",
    "                 ) -> np.ndarray:\n",
    "    \"\"\" Lucas Kanade optical flow for single frame transition\n",
    "\n",
    "    Args:\n",
    "        x_derivative (np.ndarray): x derivative I_x of shape (H, W)\n",
    "        y_derivative (np.ndarray): y derivative I_y of shape (H, W)\n",
    "        time_derivative (np.ndarray): temporal derivative I_t of shape (H, W)\n",
    "        window_size (int): Window size of W_p (square windows)\n",
    "        threshold (float): Eigen value threshold of the covariance matrix A^T A \n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: flow matrix of shape (H, W, 2) containing x and y flows.\n",
    "    \"\"\"\n",
    "    window_size = int(window_size / 2)\n",
    "    height, width = x_derivative.shape\n",
    "    flow = np.zeros((height, width, 2))\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            top = max(0, i - window_size)\n",
    "            bottom = min(height, i + window_size)\n",
    "            left = max(0, j - window_size)\n",
    "            right = min(width, j + window_size)\n",
    "            Ix = x_derivative[top:bottom, left:right]\n",
    "            Iy = y_derivative[top:bottom, left:right]\n",
    "            It = time_derivative[top:bottom, left:right]\n",
    "\n",
    "            Ix = Ix.reshape(-1, 1)\n",
    "            Iy = Iy.reshape(-1, 1)\n",
    "            b = -It.reshape(-1, 1)\n",
    "\n",
    "            A = np.hstack((Ix, Iy))\n",
    "            ATA = A.T.dot(A)\n",
    "            if np.linalg.det(ATA) < threshold:\n",
    "                flow[i, j] = [0, 0]\n",
    "            else:\n",
    "                flow[i, j] = np.linalg.inv(ATA).dot(A.T).dot(b).reshape(2)\n",
    "\n",
    "    return flow\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "for index in range(len(image_sequence) - 1):\n",
    "\n",
    "    x_derivative, y_derivative, time_derivative = derivatives(\n",
    "        image_sequence[index], image_sequence[index + 1])\n",
    "\n",
    "    uv_values = lucas_kanade(\n",
    "        x_derivative, y_derivative, time_derivative,\n",
    "        window_size=WINDOW_SIZE, threshold=THRESHOLD)\n",
    "\n",
    "    u_sequence[index] = uv_values[:, :, 0]\n",
    "    v_sequence[index] = uv_values[:, :, 1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cell below to visualize your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225410a9867e4041a2817d20e77f8b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Play(value=0, description='Play', max=318), IntSlider(value=0, max=318))), VBox(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from visualizers.flow import FlowRenderer\n",
    "\n",
    "FlowRenderer(image_sequence,\n",
    "             u_sequence,\n",
    "             v_sequence)()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 [20pt]\n",
    "\n",
    "Write your answers under the questions in the cells below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why can we not reliably compute flow for windows $\\mathcal{W}_p$ with small eigen values?\n",
    "\n",
    "Computing flow for windows with small eigenvalues can be unreliable because small eigenvalues correspond to directions in which the intensity of the image is changing slowly. When the intensity of the image is changing slowly, it can be difficult to accurately track the motion of features in the image over time. This can lead to errors in the computed flow, which can make it unreliable.\n",
    "\n",
    "Another reason that computing flow for windows with small eigenvalues can be unreliable is that these windows may not contain enough texture or distinctive features to accurately track. When there are not enough distinctive features in the window, it can be difficult to accurately determine the motion of the features that are present, which can lead to errors in the computed flow.\n",
    "\n",
    "Overall, it is generally more reliable to compute flow for windows with larger eigenvalues, as these windows tend to contain more texture and distinctive features, and the intensity of the image is changing more rapidly in these directions. This makes it easier to accurately track the motion of features over time and compute more reliable flow estimates."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain the aperture problem.\n",
    "\n",
    "The aperture problem refers to the difficulty in determining the depth of an image or scene based on a single 2D image. In order to determine the depth of an image or scene, you need to have information about the distances between different objects in the scene. This can be difficult to obtain from a single 2D image, especially if the objects in the scene have similar sizes or are at similar distances from the camera.\n",
    "\n",
    "One way to overcome the aperture problem is to use multiple cameras or viewpoints to capture images of the scene from different angles. By comparing the images from different viewpoints, it is possible to determine the depth of objects in the scene. Another approach is to use specialized sensors or techniques, such as time-of-flight sensors or structured light systems, to directly measure the depth of objects in the scene. These approaches can help to overcome the aperture problem and enable more accurate depth estimation in computer vision and image processing applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are image corners well-conditioned points for optical flow? Show your answer.\n",
    "\n",
    "Optical flow is a technique used to estimate the motion of objects in an image or video sequence. To accurately estimate the motion of an object, it is helpful to have points in the image that are easy to track over time and are not affected by noise or other factors that could interfere with the tracking. These points are known as well-conditioned points.\n",
    "\n",
    "Image corners can sometimes be well-conditioned points for optical flow estimation because they tend to have a high degree of local contrast and distinctive features, which makes it easier to track their motion over time. Image corners also tend to have a relatively small neighborhood, which means that there is less surrounding image content that can interfere with the tracking of the corner.\n",
    "\n",
    "However, image corners are not always well-conditioned points for optical flow estimation. For example, if an image corner is occluded or is too close to the edge of the image, it may be difficult to accurately track its motion. Image corners can also be affected by noise or other image artifacts, which can make it difficult to accurately estimate the flow at these locations.\n",
    "\n",
    "In summary, whether or not image corners are well-conditioned points for optical flow estimation depends on the specific characteristics of the image and the corner itself, as well as the accuracy and reliability of the optical flow algorithm being used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
